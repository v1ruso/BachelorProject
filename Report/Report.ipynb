{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bachelor project notebook\n",
    "### Musical patterns for prediction\n",
    "\n",
    "Before continuing, make sure to download and install <a href=\"https://abjad.github.io/\">abjad</a>, <a href=\"http://lilypond.org\">LilyPond</a> (needed by abjad) and <a href=\"https://github.com/craffel/pretty-midi\">pretty_midi</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need to import the libraries we will be using throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: The PÃ¤rt demo requires abjad-ext-tonality\n"
     ]
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import abjad\n",
    "import numpy as np\n",
    "import random\n",
    "# We can safely ignore the warning if there is one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll need some utility functions that will be used by the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(values, val):\n",
    "    \"\"\"\n",
    "    values: array-like.\n",
    "    val: some value of the same type as the items of values.\n",
    "    \n",
    "    This method finds the closest to \"val\" value in the array \"values\" and returns it. \n",
    "    \"\"\"\n",
    "    closest = values[0]\n",
    "    distance = float(\"inf\")\n",
    "    for d in values:\n",
    "        new_dist = abs(d-val)\n",
    "        if new_dist < distance:\n",
    "            distance = new_dist\n",
    "            closest = d\n",
    "    return closest\n",
    "\n",
    "def parse_midi(notes,round_durations=4):\n",
    "    \"\"\"\n",
    "    notes: array-like of pretty_midi Notes\n",
    "    \n",
    "    Parses each pretty_midi note into four attributes: pitches, onsets, velocities and durations.\n",
    "    \"\"\"\n",
    "    length = len(notes)\n",
    "    pitches = np.zeros(length)\n",
    "    onsets = np.zeros(length)\n",
    "    velocities = np.zeros(length)\n",
    "    durations = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        pitches[i] = notes[i].pitch\n",
    "        onsets[i] = notes[i].start\n",
    "        velocities[i] = notes[i].velocity\n",
    "        durations[i] = round(notes[i].get_duration(),round_durations)\n",
    "\n",
    "    return pitches, onsets, velocities, durations\n",
    "\n",
    "def markov_model_first_order(table,with_smoothing=False,probability_known_states=0.9):\n",
    "    \"\"\"\n",
    "    table: array-like of items to calculate a 1-order markov model from\n",
    "    with_smoothing: if set to true, will do an additive smoothing of the markov table\n",
    "        according to the histogram of \"table\"\n",
    "    probability_known_states: probability of each known event happening in the additive smoothing, must be between 0 and 1.\n",
    "    Returns a dictionary of event:probability of that event happening.\n",
    "    \"\"\"\n",
    "    assert probability_known_states>=0 and probability_known_states<=1\n",
    "    ret = {}\n",
    "    length = len(table)\n",
    "    assert length > 0\n",
    "    nb_dict = {}\n",
    "    for i in range(length-1):\n",
    "        item = table[i]\n",
    "        next_item = table[i+1]\n",
    "        if item in ret:\n",
    "            nb_dict[item] += 1\n",
    "            if next_item in ret[item]:\n",
    "                ret[item][next_item] += 1\n",
    "            else:\n",
    "                ret[item][next_item] = 1            \n",
    "        else:\n",
    "            nb_dict[item] = 1\n",
    "            ret[item] = {}\n",
    "            ret[item][next_item] = 1\n",
    "    for key_1 in ret.keys():\n",
    "        for key_2 in ret[key_1].keys():\n",
    "            ret[key_1][key_2] /= nb_dict[key_1]\n",
    "\n",
    "    # special case for the last element\n",
    "    # need to \"fallback\" -> go back to a known state\n",
    "    last_item = table[length-1]\n",
    "    if last_item not in ret:\n",
    "        ret[last_item] = {}\n",
    "        for i in range(length):\n",
    "            next_item = table[i]\n",
    "            if next_item in ret[last_item]:\n",
    "                ret[last_item][next_item] += 1\n",
    "            else:\n",
    "                ret[last_item][next_item] = 1\n",
    "        for key in ret[last_item].keys():\n",
    "            ret[last_item][key] /= length\n",
    "    if with_smoothing:\n",
    "        probability_keys = {}\n",
    "        for item in table:\n",
    "            if item in probability_keys:\n",
    "                probability_keys[item]+=1\n",
    "            else:\n",
    "                probability_keys[item]=1\n",
    "        for key in probability_keys:\n",
    "            probability_keys[key]/=length\n",
    "        # alpha smoothing for all states\n",
    "        probability_known_patterns = probability_known_states\n",
    "        probability_unknown_patterns = 1-probability_known_patterns\n",
    "        for item in ret:\n",
    "            keys_ret = list(ret.keys())\n",
    "            for key in ret[item]:\n",
    "                ret[item][key]*=probability_known_patterns\n",
    "                ret[item][key] += probability_keys[key]*probability_unknown_patterns\n",
    "                keys_ret.remove(key)\n",
    "            for key in keys_ret:\n",
    "                ret[item][key] = probability_keys[key]*probability_unknown_patterns\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And two methods to read/write from/to csv/midi files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_csv(notes,filename):\n",
    "    \"\"\"\n",
    "    notes: array-like of pretty_midi notes\n",
    "    filename: string, name of the file to write to\n",
    "    \n",
    "    Writes each note on a line into a csv file.\n",
    "    \"\"\"\n",
    "    csv = \"\"\n",
    "    for note in notes:\n",
    "        # write onto csv, each line like: start,pitch,morph_pitch,duration,channel\\n\n",
    "        # morph pitch == pitch here. It is unused, as well as the channel\n",
    "        csv += str(note.start) + \",\" + str(note.pitch) + \",\" + str(note.pitch) + \",\" + str(note.get_duration()) + \",\" + str(4) + \"\\n\"\n",
    "    file = open(filename, \"w\")\n",
    "    file.write(csv)\n",
    "    file.close()\n",
    "    \n",
    "def csv_to_notes(filename):\n",
    "    \"\"\"\n",
    "    filename: string, name of the file to read from\n",
    "    \n",
    "    Read each note from a csv file.\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    notes = list()\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            notes.append(pretty_midi.Note(velocity=80,start=float(row[0]),pitch=int(row[1]),end=float(row[0])+float(row[3])))\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple first-order Markov model\n",
    "With the utility methods now written, we can start the generation process with the simplest method: simple first-order markov model, where each note depends on the attributes of the previous notes: duration, pitch and velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_with_simple_markov(filename, patterns_to_generate = 4,with_smoothing=False,probability_known_states=0.9):\n",
    "    \"\"\"\n",
    "    filename: string of the filename to read, has to be a midi (.mid) file.\n",
    "\n",
    "    \"\"\"\n",
    "    NB_ITERATIONS = patterns_to_generate\n",
    "    notes = pretty_midi.PrettyMIDI(filename).instruments[0].notes\n",
    "    \n",
    "    \n",
    "    result = pretty_midi.PrettyMIDI()\n",
    "    result_program = pretty_midi.instrument_name_to_program(\"Acoustic Grand Piano\")\n",
    "    result_instrument = pretty_midi.Instrument(program=result_program)\n",
    "\n",
    "    # Statistic model with first order markov model\n",
    "    pitches,onsets,velocities,durations = parse_midi(notes)\n",
    "\n",
    "    # difference of onsets, will be used as durations\n",
    "    diff_onsets = onsets[1:] - onsets[:len(onsets)-1]\n",
    "\n",
    "    markov_pitches = markov_model_first_order(pitches,with_smoothing,probability_known_states)\n",
    "    markov_velocities = markov_model_first_order(velocities,with_smoothing,probability_known_states)\n",
    "    markov_diff_onsets = markov_model_first_order(diff_onsets,with_smoothing,probability_known_states)\n",
    "\n",
    "    # write current notes, each note ends when the next note starts\n",
    "    for i in range(len(notes)-1):\n",
    "        note = notes[i]\n",
    "        result_instrument.notes.append(pretty_midi.Note(velocity=note.velocity,pitch=note.pitch,start=note.start,end=notes[i+1].start))\n",
    "    # special case for last note, as there isn't a next note\n",
    "    last_note = notes[len(notes)-1]\n",
    "    result_instrument.notes.append(pretty_midi.Note(velocity=last_note.velocity,pitch=last_note.pitch,start=last_note.start,end=last_note.start + find_closest(list(markov_diff_onsets.keys()),last_note.get_duration())))\n",
    "\n",
    "    for i in range(NB_ITERATIONS):\n",
    "        last_note = result_instrument.notes[len(result_instrument.notes)-1]\n",
    "        #duration using difference of onsets\n",
    "        diff_start = find_closest(list(markov_diff_onsets.keys()),last_note.get_duration())\n",
    "        new_note_duration = random.choices(list(markov_diff_onsets[diff_start].keys()),weights=markov_diff_onsets[diff_start].values())[0]\n",
    "        # velocity\n",
    "        new_note_velocity = int(random.choices(list(markov_velocities[\n",
    "            last_note.velocity].keys()),weights=markov_velocities[last_note.velocity].values())[0])\n",
    "        # pitch\n",
    "        new_note_pitch = int(random.choices(list(markov_pitches[\n",
    "            last_note.pitch].keys()),weights=markov_pitches[last_note.pitch].values())[0])\n",
    "        # new_note\n",
    "        new_note = pretty_midi.Note(velocity=new_note_velocity,pitch=new_note_pitch,start=last_note.end,end=last_note.end+new_note_duration)\n",
    "\n",
    "        # append note to result\n",
    "        result_instrument.notes.append(new_note)\n",
    "    result.instruments.append(result_instrument)\n",
    "    # 4) Write results\n",
    "    filename = filename.split(\"/\")\n",
    "    filename = filename[len(filename)-1]\n",
    "    result.write(\"result_\" + filename[:len(filename)-3] + \"mid\")\n",
    "    # 5) Show results using abjad\n",
    "    notes_abjad = list()\n",
    "    for n in result_instrument.notes:\n",
    "        notes_abjad.append(abjad.Note(n.pitch-5*12,abjad.Duration(n.get_duration()/2).equal_or_greater_assignable))\n",
    "    staff = abjad.Staff(notes_abjad)\n",
    "    abjad.show(staff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/anaconda/lib/python3.6/site-packages/pretty_midi-0.2.9-py3.6.egg/pretty_midi/pretty_midi.py:101: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n"
     ]
    }
   ],
   "source": [
    "generate_prediction_with_simple_markov(\"midi_sample_c_major.mid\",10,with_smoothing = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String-based pattern recognition\n",
    "We can now continue with the methods to find patterns. We'll start with the exact patterns finding (string-based approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_note_equal(this,that):\n",
    "    \"\"\"\n",
    "    this: pretty_midi Note\n",
    "    that: pretty_midi Note\n",
    "    \"\"\"\n",
    "    if this==None or that==None:\n",
    "        return False\n",
    "    return this.pitch == that.pitch and this.get_duration() == that.get_duration()\n",
    "\n",
    "def find_biggest_recurring_pattern(seq):\n",
    "    \"\"\"\n",
    "    seq: array-like of pretty_midi Note.\n",
    "    \n",
    "    Returns the biggest pattern (sublist of notes) that appears at least twice, as well as the index of its first appearance in \"seq\".\n",
    "    \"\"\"\n",
    "    A = np.zeros((len(seq)+1,len(seq)+1),dtype=int)\n",
    "    res = list()\n",
    "    res_length = 0\n",
    "    index = 0\n",
    "    for i in range(1,len(seq)+1):\n",
    "        for j in range(i+1,len(seq)+1):\n",
    "            if seq[i-1]!=None and seq[j-1]!=None and is_note_equal(seq[i-1],seq[j-1]) and (j-i) > A[i-1][j-1]:\n",
    "                A[i][j] = A[i-1][j-1] + 1\n",
    "                if A[i][j] > res_length:\n",
    "                    res_length = A[i][j]\n",
    "                    index = max(i,index)\n",
    "            else:\n",
    "                A[i][j] = 0\n",
    "    if res_length > 0:\n",
    "        for i in range(index-res_length + 1, index+1):\n",
    "            res.append(seq[i-1])\n",
    "    return res, index-res_length\n",
    "\n",
    "def find_occurrences_and_indexes(seq):\n",
    "    \"\"\"\n",
    "    seq: array-like of pretty_midi Note\n",
    "    \n",
    "    Returns the sequence of notes with the biggest pattern removed, the biggest recurring pattern, and the indexes of each occurrence of that pattern.\n",
    "    \"\"\"\n",
    "    res, index_first_occurrence = find_biggest_recurring_pattern(seq)\n",
    "    if len(res)==0:\n",
    "        return seq, None, list()\n",
    "    temp_seq = seq[0:index_first_occurrence]\n",
    "    i = index_first_occurrence\n",
    "    index_occurrences = list()\n",
    "    while i < len(seq):\n",
    "        is_start = False\n",
    "        if is_note_equal(seq[i],res[0]):\n",
    "            is_start = True\n",
    "            for j in range(len(res)):\n",
    "                if i + j >= len(seq) or not is_note_equal(seq[i+j],res[j]):\n",
    "                    is_start = False\n",
    "                    break\n",
    "        if not is_start:\n",
    "            temp_seq.append(seq[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            index_occurrences.append(i)\n",
    "            for j in range(len(res)):\n",
    "                temp_seq.append(None)\n",
    "            i+=len(res)\n",
    "    return temp_seq, res, index_occurrences\n",
    "\n",
    "def find_all_occurrences_and_indexes(seq):\n",
    "    \"\"\"\n",
    "    seq: array-like of pretty_midi Note\n",
    "    \n",
    "    Finds all patterns and indexes of those patterns.\n",
    "    \"\"\"\n",
    "    list_patterns = list()\n",
    "    list_indexes = list()\n",
    "    res = list()\n",
    "    seq_x = seq\n",
    "    while res!=None:\n",
    "        seq_x, res, indexes = find_occurrences_and_indexes(seq_x)\n",
    "        if res!=None:\n",
    "            list_patterns.append(res)\n",
    "            list_indexes.append(indexes)\n",
    "    for i in range(len(seq_x)):\n",
    "        # special case for non recurring patterns: notes that appear only once\n",
    "        if seq_x[i]!=None:\n",
    "            list_patterns.append([seq_x[i]])\n",
    "            list_indexes.append([i])\n",
    "    return list_patterns,list_indexes\n",
    "\n",
    "def first_order_markov_with_patterns(seq,with_smoothing=False,probability_known_patterns=0.9):\n",
    "    \"\"\"\n",
    "    seq: array-like of pretty_midi Note.\n",
    "    \n",
    "    Returns a first-order Markov model of the patterns found in the sequence of note,\n",
    "        the list of patterns, the list of indexes, and a transformation of notes->patterns.\n",
    "    \"\"\"\n",
    "    list_patterns, list_indexes = find_all_occurrences_and_indexes(seq)\n",
    "    index_to_pattern_index = {}\n",
    "    for i in range(len(list_indexes)):\n",
    "        for j in range(len(list_indexes[i])):\n",
    "            index_to_pattern_index[list_indexes[i][j]] = i\n",
    "    pattern_indexes_seq = list()\n",
    "    if len(index_to_pattern_index.keys())>0:\n",
    "        head = 0\n",
    "        while head < len(seq):\n",
    "            pattern_indexes_seq.append(index_to_pattern_index[head])\n",
    "            head += len(list_patterns[index_to_pattern_index[head]])\n",
    "    return markov_model_first_order(pattern_indexes_seq,with_smoothing,probability_known_patterns),list_patterns,list_indexes,pattern_indexes_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_with_string_based(filename, patterns_to_generate = 4,with_smoothing=False,probability_known_patterns=0.9):\n",
    "    \"\"\"\n",
    "    filename: string of the filename to read, has to be a midi (.mid) file.\n",
    "\n",
    "    \"\"\"\n",
    "    NB_ITERATIONS = patterns_to_generate\n",
    "    seq_temp = pretty_midi.PrettyMIDI(filename).instruments[0].notes\n",
    "    \n",
    "    # 0) Transform seq_notes so it has correct durations\n",
    "    # Statistic model with first order markov model\n",
    "    _,onsets,_,_ = parse_midi(seq_temp)\n",
    "    diff_onsets = onsets[1:] - onsets[:len(onsets)-1]\n",
    "    seq = list()\n",
    "    # write current notes, each note ends when the next note starts\n",
    "    for i in range(len(seq_temp)-1):\n",
    "        note = seq_temp[i]\n",
    "        seq.append(pretty_midi.Note(velocity=note.velocity,pitch=note.pitch,start=note.start,end=seq_temp[i+1].start))\n",
    "    # special case for last note, as there isn't a next note\n",
    "    last_note = seq_temp[len(seq_temp)-1]\n",
    "    seq.append(pretty_midi.Note(velocity=last_note.velocity,pitch=last_note.pitch,start=last_note.start,end=last_note.start + find_closest(diff_onsets,last_note.get_duration())))\n",
    "  \n",
    "    # 1) Transform sequence of notes into sequence of patterns\n",
    "    markov,patterns,_,transformed_seq = first_order_markov_with_patterns(seq,with_smoothing,probability_known_patterns)\n",
    "    # 2) Generate next patterns\n",
    "    for i in range(NB_ITERATIONS):\n",
    "        last_pattern = transformed_seq[len(transformed_seq)-1]\n",
    "        next_pattern = random.choices(list(markov[last_pattern].keys()),weights=markov[last_pattern].values())[0]\n",
    "        transformed_seq.append(next_pattern)\n",
    "    \n",
    "    # 3) Transform back into notes\n",
    "    notes = list()\n",
    "    # special case for first pattern\n",
    "    first_pattern = patterns[transformed_seq[0]]\n",
    "    first_note = first_pattern[0]\n",
    "    notes.append(first_note)\n",
    "    for i in range(1,len(first_pattern)):\n",
    "        current_note = first_pattern[i]\n",
    "        previous_note = notes[len(notes)-1]\n",
    "        new_note = pretty_midi.Note(velocity=current_note.velocity,pitch=current_note.pitch,start=previous_note.end,end=previous_note.end+current_note.get_duration())\n",
    "        notes.append(new_note)\n",
    "    for i in range(1,len(transformed_seq)):\n",
    "        current_pattern = patterns[transformed_seq[i]]\n",
    "        for j in range(len(current_pattern)):\n",
    "            current_note = current_pattern[j]\n",
    "            previous_note = notes[len(notes)-1]\n",
    "            new_note = pretty_midi.Note(velocity=current_note.velocity,pitch=current_note.pitch, start = previous_note.end,end=previous_note.end + current_note.get_duration())\n",
    "            notes.append(new_note)\n",
    "    # 4) Write results\n",
    "    result = pretty_midi.PrettyMIDI()\n",
    "    result_program = pretty_midi.instrument_name_to_program(\"Acoustic Grand Piano\")\n",
    "    result_instrument = pretty_midi.Instrument(program=result_program)\n",
    "    result_instrument.notes = notes#[len(seq_temp):]\n",
    "    result.instruments.append(result_instrument)\n",
    "    filename = filename.split(\"/\")\n",
    "    filename = filename[len(filename)-1]\n",
    "    result.write(\"result_\" + filename[:len(filename)-3] + \"mid\")\n",
    "    # 5) Show results using abjad\n",
    "    notes_abjad = list()\n",
    "    for n in notes:\n",
    "        notes_abjad.append(abjad.Note(n.pitch-5*12,abjad.Duration(n.get_duration()/2).equal_or_greater_assignable))\n",
    "    staff = abjad.Staff(notes_abjad)\n",
    "    abjad.show(staff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_with_string_based(\"midi_sample_c_major.mid\",10,with_smoothing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation-based pattern recognition\n",
    "Now we'll go with the non-exact pattern approach (translation-based). Again, we'll need some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_approximate_patterns(seq_notes):\n",
    "    \"\"\"\n",
    "    Based on SIA(TEC) algorithm\n",
    "    seq_notes: list of (onset,pitch) elements\n",
    "    \n",
    "    Returns a dictionary of translation vectors: (onset,pitch).\n",
    "    \"\"\"\n",
    "    vector_matrix = np.empty((len(seq_notes),len(seq_notes)),dtype=object)\n",
    "    for i in range(len(seq_notes)): #Â rows\n",
    "        if seq_notes[i]==None:\n",
    "            continue\n",
    "        for j in range(len(seq_notes)): # columns\n",
    "            if seq_notes[j]==None:\n",
    "                continue\n",
    "            if j<i:\n",
    "                vector_matrix[i,j] = (seq_notes[i][0]-seq_notes[j][0],seq_notes[i][1]-seq_notes[j][1])\n",
    "            else:\n",
    "                vector_matrix[i,j] = (0,0)\n",
    "    result = {}\n",
    "    for i in range(len(seq_notes)):\n",
    "        if seq_notes[i]==None:\n",
    "            continue\n",
    "        for j in range(len(seq_notes)):\n",
    "            if seq_notes[j]==None:\n",
    "                continue\n",
    "            if vector_matrix[i,j][0]==0 and vector_matrix[i,j][1]==0:\n",
    "                continue\n",
    "            else:\n",
    "                if vector_matrix[i,j] in result:\n",
    "                    result[vector_matrix[i,j]].append(seq_notes[j])\n",
    "                else:\n",
    "                    result[vector_matrix[i,j]] = list()\n",
    "                    result[vector_matrix[i,j]].append(seq_notes[j])\n",
    "    return result\n",
    "\n",
    "def is_note_in_seq(note,seq):\n",
    "    \"\"\"\n",
    "    note: (onset,pitch) tuple\n",
    "    seq: list of (onset,pitch) tuples\n",
    "    \n",
    "    Returns True if note is in seq.\n",
    "    \"\"\"\n",
    "    for n in seq:\n",
    "        if n[0] == note[0] and n[1]==note[1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def are_seqs_equal(seq_1,seq_2):\n",
    "    \"\"\"\n",
    "    seq_1: list of (onset,pitch) tuples\n",
    "    seq_2: list of (onset,pitch) tuples\n",
    "    \n",
    "    Returns True if the two lists are equal.\n",
    "    \"\"\"\n",
    "    if len(seq_1)!=len(seq_2):\n",
    "        return False\n",
    "    for i in range(len(seq_1)):\n",
    "        if seq_1[i][0]!=seq_2[i][0] or seq_1[i][1]!=seq_2[i][1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def filter_patterns(patterns, notes):\n",
    "    \"\"\"\n",
    "    patterns: dictionary, keys are translation vectors, values are (onset,pitch) tuples\n",
    "        which can be transformed into other tuples using the key\n",
    "        \n",
    "    Returns a filtered version of the patterns found. Keeps only the values which don't overlap:\n",
    "    ex: pattern = [(0,1),(1,2)], translation vector =(1,1), the first note can be turned into a \n",
    "    note within the same pattern, so we remove that entry.\n",
    "    \n",
    "    And values whose notes are not continuous, let's say we have four notes:\n",
    "    [(0,0),(1,1),(2,0),(3,1)], a pattern would be [(0,0),(2,0)] and its corresponding translection vector is\n",
    "    (1,1). However, the notes in the patterns are not continuous, so we remove that entry.\n",
    "    \n",
    "    \"\"\"\n",
    "    # first transform list of notes into dictionary\n",
    "    new_patterns = {}\n",
    "    for key in patterns:\n",
    "        # transform list of notes from pattern into dictionary\n",
    "        temp_notes = {}\n",
    "        for n in patterns[key]:\n",
    "            temp_notes[n[0]]=n[1]\n",
    "        temp_pattern = list()\n",
    "        # filter patterns so that a note isn't repeated twice within a pattern\n",
    "        for n in patterns[key]:\n",
    "            new_note = (n[0]+key[0],n[1]+key[1])\n",
    "            if new_note[0] not in temp_notes:\n",
    "                temp_pattern.append(n)\n",
    "        # now we need to check if all elements are contiguous within a pattern\n",
    "        new_patterns[key] = list()\n",
    "        for i in range(len(notes)):\n",
    "            if notes[i]==None:\n",
    "                continue\n",
    "            if notes[i][0] == temp_pattern[0][0] and notes[i][1] == temp_pattern[0][1]:\n",
    "                for j in range(0,min(len(notes),len(temp_pattern))):\n",
    "                    if notes[j+i]==None:\n",
    "                        continue\n",
    "                    if notes[j+i][0] == temp_pattern[j][0] and notes[j+i][1] == temp_pattern[j][1]:\n",
    "                        new_patterns[key].append(temp_pattern[j])\n",
    "                    else:\n",
    "                        break\n",
    "    # now remove entries containing 0 or 1 note\n",
    "    result = {}\n",
    "    for key in new_patterns:\n",
    "        if len(new_patterns[key])>1:\n",
    "            result[key] = new_patterns[key]\n",
    "    return result\n",
    "\n",
    "def find_biggest_pattern_in_patterns(dict):\n",
    "    \"\"\"\n",
    "    dict: dictionary of translation vector->pattern\n",
    "    \n",
    "    Returns the biggest pattern and its corresponding translation vector.\n",
    "    \"\"\"\n",
    "    max_length = -1\n",
    "    pattern = None\n",
    "    trans_vector = None\n",
    "    for key in dict:\n",
    "        if len(dict[key])>max_length:\n",
    "            max_length=len(dict[key])\n",
    "            trans_vector = key\n",
    "            pattern = dict[key]\n",
    "    return pattern, trans_vector\n",
    "\n",
    "def find_all_trans_vector_with_pattern(dict,pattern):\n",
    "    \"\"\"\n",
    "    dict: dictionary of translation vector->pattern\n",
    "    pattern: list of (onset,pitch)\n",
    "    \n",
    "    Returns all translation vectors which have the same pattern as key\n",
    "    \"\"\"\n",
    "    ret = list()\n",
    "    for key in dict:\n",
    "        if are_seqs_equal(pattern,dict[key]):\n",
    "            ret.append(key)\n",
    "    return ret\n",
    "\n",
    "def find_pattern_with_indices(seq,list_patterns,pattern_to_indices,index_pattern):\n",
    "    \"\"\"\n",
    "    seq: list of (onset,pitch) elements\n",
    "    pattern_to_indices: already existent patterns\n",
    "    index_pattern: key where to add the new pattern, i.e. pattern_to_indices[index_pattern] = ...\n",
    "    This method is supposed to find one pattern.\n",
    "    \"\"\"\n",
    "    result = find_approximate_patterns(seq)\n",
    "    result_filter = filter_patterns(result,seq)\n",
    "    pattern,trans_vector = find_biggest_pattern_in_patterns(result_filter)\n",
    "    if pattern!=None:\n",
    "        all_trans_vectors = find_all_trans_vector_with_pattern(result_filter,pattern)\n",
    "        all_trans_vectors.insert(0,(0,0))\n",
    "        index_before = index_pattern\n",
    "        ret_trans_vectors = list()\n",
    "        for trans in all_trans_vectors:\n",
    "\n",
    "            first_trans_note = (pattern[0][0]+trans[0],pattern[0][1]+trans[1])\n",
    "            length_pattern = len(pattern)\n",
    "            i = 0\n",
    "            current_pattern = list()\n",
    "            while i < len(seq):\n",
    "                current_note = seq[i]\n",
    "                if current_note!=None and current_note[0]==first_trans_note[0] and current_note[1] == first_trans_note[1]:\n",
    "                    pattern_to_indices[index_pattern] = i\n",
    "                    for j in range(length_pattern):\n",
    "                        trans_note = (pattern[j][0]+trans[0],pattern[j][1]+trans[1])\n",
    "                        current_pattern.append(trans_note)\n",
    "                        seq[i+j] = None\n",
    "                    break\n",
    "                else:\n",
    "                    i+=1\n",
    "            if len(current_pattern)!=0:\n",
    "                index_pattern+=1\n",
    "                ret_trans_vectors.append(trans)\n",
    "                list_patterns.append(current_pattern)\n",
    "        return pattern,index_pattern,ret_trans_vectors\n",
    "    return pattern,index_pattern,None\n",
    "\n",
    "def is_list_empty(seq):\n",
    "    \"\"\"\n",
    "    Checks whether \"seq\" containes only None values\n",
    "    \"\"\"\n",
    "    for n in seq:\n",
    "        if n!=None:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_all_patterns(seq):\n",
    "    \"\"\"\n",
    "    finds all patterns in a list of (onset,pitch) tuples.\n",
    "    Ex: let a certain sequence be 0,1,2,0,1,2,2,3,4,1,3,1,3\n",
    "    Then a first pattern would be [0,1,2], appearing three times, \n",
    "    the third time being shifted up by 2 ([2,3,4]).\n",
    "    A second pattern would be [1,3], appearing twice.\n",
    "    In this case, the function should return:\n",
    "    list_patterns = [[0,1,2],[0,1,2],[2,3,4],[1,3],[1,3]]\n",
    "    patterns_to_indices = {\n",
    "        0: 0,\n",
    "        1: 3,\n",
    "        2: 6,\n",
    "        3: 9,\n",
    "        4: 11\n",
    "    }\n",
    "    \"\"\"\n",
    "    list_patterns = list()\n",
    "    pattern_to_indices = {}\n",
    "    index_pattern = 0\n",
    "    trans_vectors = list()\n",
    "    while not is_list_empty(seq):\n",
    "        pattern,index_pattern,all_trans_vectors = find_pattern_with_indices(seq,list_patterns,pattern_to_indices,index_pattern)\n",
    "        if pattern==None: #Â case only one note at the end\n",
    "            for i in range(len(seq)):\n",
    "                if seq[i]!=None:\n",
    "                    list_patterns.append([seq[i]])\n",
    "                    pattern_to_indices[index_pattern] = i\n",
    "                    index_pattern+=1\n",
    "                    trans_vectors.append((0,0))\n",
    "            break\n",
    "        for i in range(len(all_trans_vectors)):\n",
    "            trans_vectors.append(all_trans_vectors[i])\n",
    "    return list_patterns,pattern_to_indices,trans_vectors\n",
    "\n",
    "\n",
    "def collapse_pattern_to_indices(trans_vectors):\n",
    "    \"\"\"\n",
    "    trans_vectors: list of translation vectors\n",
    "    \n",
    "    Let's say we have the following translation vectors:\n",
    "    [(0,0),(1,0),(0,0),(2,1),(0,0)], then for the generation process, we'll\n",
    "    need to have different patterns if the translation vectors are different in their second value.\n",
    "    So technically, (0,0) and (1,0) are the same patterns, only time-shifted. However,\n",
    "    (0,0) and (2,1) are different, as they are vertically shifted.\n",
    "    \"\"\"\n",
    "    trans_vectors.append((0,0))\n",
    "    collapsed_indices_to_pattern = {}\n",
    "    current_index = 0\n",
    "    i = 0\n",
    "    while i<len(trans_vectors)-1:\n",
    "        trans_v = trans_vectors[i]\n",
    "        if trans_v[0]==0 and trans_v[1]==0:\n",
    "            temp_dict = {}\n",
    "            temp_index = 0.0\n",
    "            temp_dict[temp_index] = list()\n",
    "            temp_dict[temp_index].append(i)\n",
    "            for j in range(i+1,len(trans_vectors)):\n",
    "                current_trans = trans_vectors[j]\n",
    "                if current_trans[0]==0 and current_trans[1]==0:\n",
    "                    for key in temp_dict:\n",
    "                        collapsed_indices_to_pattern[current_index] = temp_dict[key]\n",
    "                        current_index+=1\n",
    "                    break\n",
    "                if current_trans[1] not in temp_dict:\n",
    "                    temp_dict[current_trans[1]] = list()\n",
    "                temp_dict[current_trans[1]].append(j)\n",
    "            else:\n",
    "                continue\n",
    "        i+=1\n",
    "    return collapsed_indices_to_pattern\n",
    "\n",
    "\n",
    "def transform_collapsed_and_indices(collapsed,pattern_to_indices):\n",
    "    \"\"\"\n",
    "    Takes results from collapse_pattern_to_indices and patterns to indices and \n",
    "    returns the indices of each pattern within the sequence of notes\n",
    "    \"\"\"\n",
    "    true_indices = {}\n",
    "    for key in collapsed:\n",
    "        true_indices[key] = list()\n",
    "        for val in collapsed[key]:\n",
    "            true_indices[key].append(pattern_to_indices[val])\n",
    "    return true_indices\n",
    "\n",
    "def transform_back_into_seq(true_indices):\n",
    "    reversed_indices = {}\n",
    "    for key in true_indices:\n",
    "        for val in true_indices[key]:\n",
    "            reversed_indices[val] = key\n",
    "    seq = list()\n",
    "    keys = list(reversed_indices.keys())\n",
    "    keys.sort()\n",
    "    for val in keys:\n",
    "        seq.append(reversed_indices[val])\n",
    "    return seq\n",
    "\n",
    "def midi_notes_to_tuples(notes):\n",
    "    \"\"\"\n",
    "    converts a sequence of pretty_midi notes into a list of (onset,pitch) elements\n",
    "    \"\"\"\n",
    "    seq = list()\n",
    "    for n in notes:\n",
    "        seq.append((n.start,n.pitch))\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the utility functions are written, we can generate a continuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_with_translation_based(filename, patterns_to_generate = 4,with_smoothing=False,probability_known_patterns=0.9):\n",
    "    \"\"\"\n",
    "    filename: string of the filename to read, has to be a midi (.mid) file.\n",
    "\n",
    "    \"\"\"\n",
    "    NB_ITERATIONS = patterns_to_generate\n",
    "    seq_temp = pretty_midi.PrettyMIDI(filename).instruments[0].notes\n",
    "    \n",
    "    # 0) Transform seq_temp so it has correct durations\n",
    "    _,onsets,_,_ = parse_midi(seq_temp)\n",
    "    diff_onsets = onsets[1:] - onsets[:len(onsets)-1]\n",
    "    notes = list()\n",
    "    #Â write current notes, each note ends when the next note starts\n",
    "    for i in range(len(seq_temp)-1):\n",
    "        note = seq_temp[i]\n",
    "        notes.append(pretty_midi.Note(velocity=note.velocity,pitch=note.pitch,start=note.start,end=seq_temp[i+1].start))\n",
    "    # special case for last note, as there isn't a next note\n",
    "    last_note = seq_temp[len(seq_temp)-1]\n",
    "    notes.append(pretty_midi.Note(velocity=last_note.velocity,pitch=last_note.pitch,start=last_note.start,end=last_note.start + find_closest(diff_onsets,last_note.get_duration())))\n",
    "\n",
    "    tuples = midi_notes_to_tuples(seq_temp)\n",
    "\n",
    "    # 1) Transform sequence of notes into sequence of patterns \n",
    "    list_patterns,pattern_to_indices,trans_vectors = find_all_patterns(tuples)\n",
    "    collapsed = collapse_pattern_to_indices(trans_vectors)\n",
    "    true_indices = transform_collapsed_and_indices(collapsed,pattern_to_indices)\n",
    "    seq = transform_back_into_seq(true_indices)\n",
    "    mm1 = markov_model_first_order(seq,with_smoothing,probability_known_patterns)\n",
    "    # 2) Generate next patterns\n",
    "    for i in range(NB_ITERATIONS):\n",
    "        last_pattern = seq[len(seq)-1]\n",
    "        next_pattern = random.choices(list(mm1[last_pattern].keys()),weights=mm1[last_pattern].values())[0]\n",
    "        seq.append(next_pattern)\n",
    "    # 3) Transform back into notes\n",
    "    # need to use collapsed, and list of patterns and seq\n",
    "    notes_to_write = list()\n",
    "    # need index first pattern and length of pattern\n",
    "    first_pattern = notes[true_indices[seq[0]][0]:true_indices[seq[0]][0]+len(list_patterns[collapsed[seq[0]][0]])]\n",
    "    first_note = first_pattern[0]\n",
    "    notes_to_write.append(first_note)\n",
    "    for i in range(1,len(first_pattern)):\n",
    "        current_note = first_pattern[i]\n",
    "        previous_note = notes_to_write[len(notes_to_write)-1]\n",
    "        new_note = pretty_midi.Note(velocity=current_note.velocity,pitch=current_note.pitch,start=previous_note.end,end=previous_note.end+current_note.get_duration())\n",
    "        notes_to_write.append(new_note)\n",
    "    for i in range(1,len(seq)):\n",
    "        current_pattern = notes[true_indices[seq[i]][0]:true_indices[seq[i]][0]+len(list_patterns[collapsed[seq[i]][0]])]\n",
    "        for j in range(len(current_pattern)):\n",
    "            current_note = current_pattern[j]\n",
    "            previous_note = notes_to_write[len(notes_to_write)-1]\n",
    "            new_note = pretty_midi.Note(velocity=current_note.velocity,pitch=current_note.pitch, start = previous_note.end,end=previous_note.end + current_note.get_duration())\n",
    "            notes_to_write.append(new_note)\n",
    "    # 4) Write results\n",
    "    result = pretty_midi.PrettyMIDI()\n",
    "    result_program = pretty_midi.instrument_name_to_program(\"Acoustic Grand Piano\")\n",
    "    result_instrument = pretty_midi.Instrument(program=result_program)\n",
    "    result_instrument.notes = notes_to_write#[len(seq_temp):]\n",
    "    result.instruments.append(result_instrument)\n",
    "    filename = filename.split(\"/\")\n",
    "    filename = filename[len(filename)-1]\n",
    "    result.write(\"result_\" + filename[:len(filename)-3] + \"mid\")\n",
    "    # 5) Show results using abjad\n",
    "    notes_abjad = list()\n",
    "    for n in notes_to_write:\n",
    "        notes_abjad.append(abjad.Note(n.pitch-5*12,abjad.Duration(n.get_duration()/2).equal_or_greater_assignable))\n",
    "    staff = abjad.Staff(notes_abjad)\n",
    "    abjad.show(staff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prediction_with_translation_based(\"midi_sample_c_major.mid\",20,with_smoothing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
